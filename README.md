# ğŸ§¾ Claims Processor â€” Generative AIâ€“Powered Intelligent Claims Processing

A lightweight, end-to-end claims automation pipeline for insurance companies â€” powered by OCR, NLP, and Generative AI.
This system ingests raw claim documents (PDFs, images, text), extracts key information, validates it, and enables human-in-the-loop review for low-confidence data points.

---

## âœ¨ Overview

Modern insurance operations handle hundreds of claim documents daily â€” often scanned, handwritten, or poorly structured. Manual data entry is slow, error-prone, and expensive. Claims Processor automates this process through:

- ğŸ“¥ Document ingestion (PDF, image, text)
- ğŸ§  OCR + Entity Extraction (form fields, amounts, names, dates)
- âœï¸ Generative AI summarization & normalization
- âœ… Rule-based validation & HITL flagging
- ğŸ§¾ Structured output with audit trail

The project is modular so you can extend or replace components (OCR engine, LLM provider, DB, cloud provider).

---

## ğŸš€ Features

- Ingest PDFs, images, and text documents
- OCR text extraction (pytesseract + pdfplumber)
- Entity extraction with spaCy and regex helpers
- GenAI-based summarization & normalization using OpenAI APIs
- Rule-based validation via `configs/rules.yaml`
- Human-in-the-loop (HITL) workflow for low-confidence fields
- Full traceability: raw file â†’ processed JSON â†’ reviewer actions

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Claim   â”‚
â”‚ (PDF/Image)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Ingest
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OCR & Parser â”‚â”€â”€â”€â–º Structured Fields
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GenAI Layer â”‚â”€â”€â”€â–º Summarized & Normalized Data
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validation & â”‚â”€â”€â”€â–º Flag low-confidence
â”‚   Rules      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HITL Review  â”‚â”€â”€â”€â–º Final Approved Output
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Proposed AWS Deployment (conceptual)

| Component | AWS Service | Purpose |
|---|---|---|
| File Storage | Amazon S3 | Store raw and processed claim documents |
| Processing Backend | AWS Lambda / Amazon ECS | Stateless OCR & AI processing |
| Queue & Event Triggers | Amazon SQS | Decouple ingestion from processing |
| OCR & NLP | Amazon Textract + OpenAI API | AI-powered text extraction & summarization |
| Database | Amazon RDS / DynamoDB | Store metadata and reviewer actions |
| HITL Interface | Streamlit / Amplify | Reviewer UI for flagged claims |
| Secrets & Encryption | Secrets Manager / KMS | Secure API keys and data |
| Monitoring | CloudWatch | Pipeline observability |

---

## ğŸ›¡ï¸ Security & Compliance

- ğŸ” Sensitive data encrypted at rest (KMS in cloud setups)
- ğŸ”‘ Secrets and API keys stored in Secrets Manager or environment variables
- ğŸ‘¤ Fine-grained IAM roles for services and reviewers
- ğŸ§¾ Reviewer actions are logged for auditability
- ğŸªª PII redaction performed in processing pipeline

---

## ğŸ§° Tech Stack

- Language: Python 3.13 (works on 3.11+)
- OCR: Tesseract, pdfplumber
- NLP: spaCy, regex helpers
- GenAI: OpenAI GPT APIs
- Validation: YAML-based rules
- UI: Streamlit (optional)
- Containerization: Docker

---

## ğŸ§ª Local Quickstart

### Requirements

- Python 3.11+
- Tesseract OCR installed locally (for image/PDF OCR)
- Set `OPENAI_API_KEY` in `.env` if using GenAI features
- Install pip packages from `requirements.txt`

### Clone & install

```powershell
git clone https://github.com/yourname/claims_processor.git
cd claims_processor
python -m pip install -r requirements.txt
```

### Run a processing example

```powershell
python -m src.main --input data/raw/mock_claim_20251008_070054.txt
```

### Run tests

```powershell
pytest -q
```

---

## ğŸ§­ Configuration

| File | Purpose |
|---|---|
| `configs/schema.json` | Defines structured claim fields |
| `configs/prompts.yaml` | Prompt templates for LLM normalization |
| `configs/rules.yaml` | Business validation rules |
| `.env` | Environment variables (API keys, DB URLs) |
| `data/` | Raw and processed claim files |
| `db/` | Local SQLite DB for HITL prototype |

---

## ğŸ§‘â€ğŸ’» Human-in-the-Loop (HITL) Workflow

1. Low-confidence fields are flagged by `validation`.
2. Flagged claims are stored in the local DB for review.
3. Reviewers use the Streamlit UI to confirm or correct fields.
4. Final approved JSON is stored in `data/processed/` along with reviewer metadata.

---

## ğŸ“ˆ Business Impact

- â³ Reduce manual data entry and turnaround time
- ğŸ§® Increase data accuracy via automated validation
- ğŸ§¾ Provide full traceability for audits and compliance
- ğŸ§‘â€âš–ï¸ Empower auditors & reviewers with HITL dashboard

---

## ğŸ› ï¸ Extending to Production

- Replace local ingestion with S3 or API-based upload
- Swap SQLite for RDS/Postgres and configure via `DATABASE_URL`
- Run processing as stateless workers (Lambda / ECS) behind SQS
- Add RBAC and authentication for reviewer UI
- Integrate with insurance core systems via webhooks/APIs

---

## ğŸ Troubleshooting

- OCR errors: Ensure Tesseract and language packs installed; increase PDF DPI for scanned documents.
- OpenAI/API errors: Verify `OPENAI_API_KEY` in `.env` and network connectivity.
- Validation failures: Inspect `configs/rules.yaml` and thresholds.
- Tests failing: Run `pytest -q -k <test_name>` to isolate.

---

## ğŸ“¸ Demo (Optional)

Upload claim document â†’ Auto process â†’ HITL Review â†’ Final Output JSON.

Add screenshots or a Loom recording link here for a quick demo.

---

## ğŸ“œ License

MIT License â€” see the `LICENSE` file.

---

## ğŸ“¬ Contact

Open issues or PRs on GitHub. For quick help, open a discussion with your environment and a minimal reproducer.
